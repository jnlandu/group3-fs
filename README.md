# Group 3: Feature Selection

## Abstract:
This is the repository for the feature selection project, a class assignment where the authors presented a brief report on Feature selection methods in machine learning.  Feature selection is  crucial pre-processing technique in machine learning. It encompasses dimensionality techniques  used to select features relevant features and remove redundant ones. It has shown several benefits, such : preventing overfitting, dimensionality reduction, increassing the learning process and the accuracy of models. Feature selection methods are discussed, challenges and good practices provided, and a case study on the LASSO method concludes the report


## Feature selections(FS):
The FS methods can be categorized in three: supervised, unsupervised, and semi-supervised. They all 3 depend on the learning task being solved.

<img src="chart1" alt="chart1">

## Feature Selection Methods:

### Filter Methods
Filter methods are feature selection techniques that are independent of any learning algorithms
i.e. model-agnostic. They assess feature importance based on statistical properties or relationships
between features and the target variable. Typically, these methods rank features according to criteria
such as correlation, statistical significance, and information gain, filtering out low-ranking features
and retaining the most relevant ones. 


